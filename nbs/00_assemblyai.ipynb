{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp assemblyai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# assemblyai\n",
    "\n",
    "> Simple API for quickly transcribing and understanding audio/video files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore.utils import *\n",
    "import requests\n",
    "import time\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def read_file(filename, chunk_size=5242880):\n",
    "    with open(filename, 'rb') as _file:\n",
    "        while True:\n",
    "            data = _file.read(chunk_size)\n",
    "            if not data:\n",
    "                break\n",
    "            yield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "submit_transcript = \"https://api.assemblyai.com/v2/transcript\" # AssemblyAI endpoint\n",
    "upload_local_file_endpoint = 'https://api.assemblyai.com/v2/upload' # Upload Local file\n",
    "\n",
    "class AssemblyAI:\n",
    "    ''' AssemblAI class for transcribing '''\n",
    "    __version__ = '0.0.8'\n",
    "    def __init__(self, #AssemblyAI\n",
    "                 api_key:str # AssemblyAI API Key, Get it for free from https://app.assemblyai.com/\n",
    "                ):\n",
    "        self.api_key = api_key\n",
    "    \n",
    "    \n",
    "    def get_headers(self):\n",
    "        return {\"authorization\": self.api_key, \"content-type\": \"application/json\"}\n",
    "    \n",
    "    \n",
    "    def get_status_of_transcription(self,\n",
    "                                    transcripiton_id: str) -> str:\n",
    "        endpoint = f\"{submit_transcript}/{transcripiton_id}\"\n",
    "        response = requests.get(endpoint, headers=self.get_headers())\n",
    "        \n",
    "        return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "@patch \n",
    "def upload_local_file(self: AssemblyAI, \n",
    "                      local_file_path: str, # Local Audio File path\n",
    "                     ):\n",
    "    ''' Upload the local file and get audio_url in response, which can be used to sumbit for transcription'''\n",
    "    try:\n",
    "        if exists(local_file_path):\n",
    "            response = requests.post('https://api.assemblyai.com/v2/upload',\n",
    "                            headers=self.get_headers(),\n",
    "                            data=read_file(local_file_path))\n",
    "            return response.json().get('upload_url')\n",
    "    except BaseException as e:\n",
    "        print(f'Error in processing local audio file: {e}')\n",
    "\n",
    "    return {'error': 'Provided File has issues'}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def submit_audio_for_transcription(self:AssemblyAI,\n",
    "                                   audio_url: str='', #Audio URL\n",
    "                                   local_audio_file_path: str ='', # Local Audio File Path. Provide `audio_url` or `local_audio_file_path` . If both are provided, audio_url is used by default.   \n",
    "                                   sentiment_analysis: bool = False, # Include Sentiment Analysis\n",
    "                                   auto_chapters: bool = False, # Include Auto Chapaters\n",
    "                                   entity_detection: bool = False, # Include Entity Detection\n",
    "                                   auto_highlights: bool = False, # Include Auto Highlights \n",
    "                                   summarization: bool = False, # Include Summary \n",
    "                                   summary_type: str = \"bullets\", # If summary is included select `summary_type` from list [`bullets', 'bullets_verbose', 'gist', 'paragraph', 'headline']. Check out this for more details: https://www.assemblyai.com/docs/audio-intelligence#summarization \n",
    "                                   ):\n",
    "        ''' Submit Audio URL or the Local file Path for Transcription '''\n",
    "        \n",
    "        if local_audio_file_path and not audio_url:\n",
    "            audio_url = self.upload_local_file(local_audio_file_path)\n",
    "        \n",
    "        json = {\n",
    "            \"audio_url\": audio_url,\n",
    "            \"sentiment_analysis\": sentiment_analysis,\n",
    "            \"auto_chapters\": auto_chapters,\n",
    "            \"entity_detection\": entity_detection,\n",
    "            \"auto_highlights\": auto_highlights,\n",
    "        }\n",
    "        \n",
    "        json = {**json, 'summarization': True, 'summary_type': summary_type} if summarization else json\n",
    "            \n",
    "        \n",
    "        response = requests.post(submit_transcript, json=json, headers=self.get_headers())\n",
    "        return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def submit_url_for_transcription(self:AssemblyAI,\n",
    "                                   audio_url: str='', #Audio URL\n",
    "                                   sentiment_analysis: bool = False, # Include Sentiment Analysis\n",
    "                                   auto_chapters: bool = False, # Include Auto Chapaters\n",
    "                                   entity_detection: bool = False, # Include Entity Detection\n",
    "                                   auto_highlights: bool = False, # Include Auto Highlights \n",
    "                                   summarization: bool = False, # Include Summary \n",
    "                                   summary_type: str = \"bullets\", # If summary is included select `summary_type` from list [`bullets', 'bullets_verbose', 'gist', 'paragraph', 'headline']. Check out this for more details: https://www.assemblyai.com/docs/audio-intelligence#summarization \n",
    "                                   ):\n",
    "    ''' Submit Audio URL or the Local file Path for Transcription '''\n",
    "    return self.submit_audio_for_transcription(audio_url,\n",
    "                                               sentiment_analysis,\n",
    "                                               auto_chapters,\n",
    "                                               entity_detection, \n",
    "                                               auto_chapters,\n",
    "                                               summarization,\n",
    "                                               summary_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def get_transcription_results(self:AssemblyAI,\n",
    "                              transcripiton_id: str, # Transcrption ID that we got from `submit_url_for_transcription`\n",
    "                              all_details: bool = False # Include All the details, by default it `text` and `id` are returned\n",
    "                             ):\n",
    "    \"\"\"Get the transcription results for the given id\"\"\"\n",
    "    full_details = self.get_status_of_transcription(transcripiton_id)\n",
    "    status = full_details.get(\"status\")\n",
    "    while status not in [\"completed\", \"error\"]:\n",
    "        time.sleep(5)  # sleep for secs\n",
    "        full_details = self.get_status_of_transcription(transcripiton_id)\n",
    "        status = full_details.get(\"status\")\n",
    "\n",
    "    if all_details:\n",
    "        return full_details\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"id\": full_details.get(\"id\"),\n",
    "        \"confidence\": full_details.get(\"confidence\"),\n",
    "        \"text\": full_details.get(\"text\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
